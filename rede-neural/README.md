# ğŸ§  ClassificaÃ§Ã£o de GrÃ£os com CNN

ğŸ”— [Acesse o notebook no Google Colab](https://colab.research.google.com/drive/1iF4wi6bfb_TDnMz1tsUZbnzJs0pJSTyl?authuser=1)

Este projeto tem como objetivo treinar um modelo de **rede neural convolucional (CNN)** para **classificar grÃ£os de cafÃ©** em duas categorias: `grÃ£os inteiros` e `grÃ£os quebrados`. O projeto foi desenvolvido no Google Colab com suporte ao Google Drive e bibliotecas de machine learning modernas.

---

## ğŸ“ Estrutura do Projeto

```
ğŸ“¦ /img/dataset/
 â”£ ğŸ“‚ train/
 â”ƒ â”£ ğŸ“‚ grao_inteiro/
 â”ƒ â”— ğŸ“‚ grao_quebrado/
 â”£ ğŸ“‚ test/
 â”ƒ â”£ ğŸ“‚ grao_inteiro/
 â”ƒ â”— ğŸ“‚ grao_quebrado/
```

---

## ğŸ”§ Tecnologias e Bibliotecas

- Python
- NumPy, Matplotlib, Seaborn
- TensorFlow/Keras
- Scikit-learn

---

## âš™ï¸ PrÃ©-processamento

- Reescalonamento dos pixels (`rescale=1./255`)
- Aumento de dados com:
  - RotaÃ§Ã£o, zoom, deslocamento e flip horizontal
- SeparaÃ§Ã£o de 20% dos dados de treino para validaÃ§Ã£o automÃ¡tica

---

## ğŸ§  Arquitetura da Rede Neural

A rede neural construÃ­da para este projeto Ã© do tipo **Convolutional Neural Network (CNN)** e possui a seguinte estrutura:

- **Entrada**: imagens RGB com tamanho 64x64 pixels.
- **Camadas convolucionais**:
  - 1Âª camada: 128 filtros, kernel 3x3, ativaÃ§Ã£o ReLU, seguida de max pooling 2x2 e dropout de 30%.
  - 2Âª camada: 64 filtros, kernel 3x3, ativaÃ§Ã£o ReLU, seguida de max pooling 2x2 e dropout de 30%.
  - 3Âª camada: 32 filtros, kernel 3x3, ativaÃ§Ã£o ReLU, seguida de max pooling 2x2 e dropout de 30%.
- **Flatten**: achatamento dos mapas de ativaÃ§Ã£o.
- **Camadas densas**:
  - 6 camadas densas sucessivas com 256, 128, 64, 32, 16 e 8 neurÃ´nios, todas com ativaÃ§Ã£o ReLU e dropout variando entre 20% e 30%.
- **SaÃ­da**: 1 neurÃ´nio com ativaÃ§Ã£o sigmoid para classificaÃ§Ã£o binÃ¡ria (`0 = grÃ£o quebrado`, `1 = grÃ£o inteiro`).

---

## ğŸ‹ï¸â€â™€ï¸ Treinamento

- Otimizador: `Adam` com `learning_rate=0.0005`
- FunÃ§Ã£o de perda: `binary_crossentropy`
- MÃ©trica: `accuracy`
- Ã‰pocas: `350`
- Uso de `class_weight` para balancear as classes

---

## ğŸ“Š AvaliaÃ§Ã£o do Modelo

- **AcurÃ¡cia no conjunto de teste:** `92,11%`
- **Matriz de ConfusÃ£o:**
  - Mostra a distribuiÃ§Ã£o de acertos e erros
- **RelatÃ³rio de ClassificaÃ§Ã£o:**
  - GrÃ£o Inteiro:
    - Precision: 1.00
    - Recall: 0.86
  - GrÃ£o Quebrado:
    - Precision: 0.84
    - Recall: 1.00
- **MÃ©tricas Derivadas:**
  - PrecisÃ£o: 0.84
  - Sensibilidade: 1.00
  - Especificidade: 0.86
  - F1-Score: 0.91

---

## ğŸ“ˆ GrÃ¡ficos Gerados

- AcurÃ¡cia e erro por Ã©poca (train vs validation)
- Matriz de confusÃ£o com anotaÃ§Ãµes
- RelatÃ³rio de classificaÃ§Ã£o (Scikit-learn)

---

## ğŸ—‚ï¸ ExecuÃ§Ã£o

Para rodar este projeto:

1. Suba os dados no Google Drive no caminho `/Colab Notebooks/img/dataset`
2. Execute o notebook `TrabalhoFinal.ipynb` no Google Colab
3. O cÃ³digo monta o Google Drive automaticamente e treina o modelo com os dados

---

## ğŸ“Œ ObservaÃ§Ãµes

- O modelo pode ser ajustado com tÃ©cnicas de regularizaÃ§Ã£o e tuning de hiperparÃ¢metros.
- Os dados de entrada devem estar organizados em pastas por classe (`grao_inteiro` e `grao_quebrado`).
